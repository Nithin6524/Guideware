{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the filtered dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_11748\\155152889.py:2: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./borg_traces_data.csv')\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading the filtered dataset...\")\n",
    "df = pd.read_csv('./borg_traces_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic Dataset Information ===\n",
      "Dataset Shape: (405894, 34)\n",
      "\n",
      "Number of columns: 34\n",
      "\n",
      "Column names:\n",
      "- Unnamed: 0, int64\n",
      "- time, int64\n",
      "- instance_events_type, int64\n",
      "- collection_id, int64\n",
      "- scheduling_class, int64\n",
      "- collection_type, int64\n",
      "- priority, int64\n",
      "- alloc_collection_id, int64\n",
      "- instance_index, int64\n",
      "- machine_id, int64\n",
      "- resource_request, object\n",
      "- constraint, object\n",
      "- collections_events_type, int64\n",
      "- user, object\n",
      "- collection_name, object\n",
      "- collection_logical_name, object\n",
      "- start_after_collection_ids, object\n",
      "- vertical_scaling, float64\n",
      "- scheduler, float64\n",
      "- start_time, int64\n",
      "- end_time, int64\n",
      "- average_usage, object\n",
      "- maximum_usage, object\n",
      "- random_sample_usage, object\n",
      "- assigned_memory, float64\n",
      "- page_cache_memory, float64\n",
      "- cycles_per_instruction, float64\n",
      "- memory_accesses_per_instruction, float64\n",
      "- sample_rate, float64\n",
      "- cpu_usage_distribution, object\n",
      "- tail_cpu_usage_distribution, object\n",
      "- cluster, int64\n",
      "- event, object\n",
      "- failed, object\n"
     ]
    }
   ],
   "source": [
    "# Basic Information\n",
    "print(\"\\n=== Basic Dataset Information ===\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nNumber of columns:\", len(df.columns))\n",
    "print(\"\\nColumn names:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}, {df[col].dtype}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Duration Calculation ===\n",
      "\n",
      "Sample rows:\n",
      "      start_time       end_time\n",
      "0   274800000000   275100000000\n",
      "1  1800713000000  1800714000000\n",
      "2    81300000000    81600000000\n",
      "3  1075500000000  1075800000000\n",
      "4  1565315000000  1565317000000\n",
      "\n",
      "Calculated durations (in nanoseconds):\n",
      "0    300000000\n",
      "1      1000000\n",
      "2    300000000\n",
      "3    300000000\n",
      "4      2000000\n",
      "dtype: int64\n",
      "\n",
      "Adding duration column to full dataset...\n"
     ]
    }
   ],
   "source": [
    "# First, let's look at a few sample rows to verify the calculation\n",
    "print(\"\\n=== Sample Duration Calculation ===\")\n",
    "sample_rows = df[['start_time', 'end_time']].head(5)\n",
    "print(\"\\nSample rows:\")\n",
    "print(sample_rows)\n",
    "\n",
    "# Calculate duration for sample rows\n",
    "sample_duration = sample_rows['end_time'] - sample_rows['start_time']\n",
    "print(\"\\nCalculated durations (in nanoseconds):\")\n",
    "print(sample_duration)\n",
    "\n",
    "# After verifying, add duration column to full dataset\n",
    "print(\"\\nAdding duration column to full dataset...\")\n",
    "df['duration'] = df['end_time'] - df['start_time']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing start_time and end_time columns...\n",
      "\n",
      "Verifying columns after removal:\n",
      "['Unnamed: 0', 'time', 'instance_events_type', 'collection_id', 'scheduling_class', 'collection_type', 'priority', 'alloc_collection_id', 'instance_index', 'machine_id', 'resource_request', 'constraint', 'collections_events_type', 'user', 'collection_name', 'collection_logical_name', 'start_after_collection_ids', 'vertical_scaling', 'scheduler', 'average_usage', 'maximum_usage', 'random_sample_usage', 'assigned_memory', 'page_cache_memory', 'cycles_per_instruction', 'memory_accesses_per_instruction', 'sample_rate', 'cpu_usage_distribution', 'tail_cpu_usage_distribution', 'cluster', 'event', 'failed', 'duration']\n"
     ]
    }
   ],
   "source": [
    "# Remove start_time and end_time columns since we have duration_seconds\n",
    "print(\"\\nRemoving start_time and end_time columns...\")\n",
    "df = df.drop(['start_time', 'end_time'], axis=1)\n",
    "\n",
    "print(\"\\nVerifying columns after removal:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['average_usage', 'resource_request', 'maximum_usage', 'cpu_usage_distribution', \n",
    "         'tail_cpu_usage_distribution', 'assigned_memory', 'page_cache_memory', \n",
    "         'duration','vertical_scaling','event','failed']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking data types of columns:\n",
      "average_usage                   object\n",
      "resource_request                object\n",
      "maximum_usage                   object\n",
      "cpu_usage_distribution          object\n",
      "tail_cpu_usage_distribution     object\n",
      "assigned_memory                float64\n",
      "page_cache_memory              float64\n",
      "duration                         int64\n",
      "vertical_scaling               float64\n",
      "event                           object\n",
      "failed                          object\n",
      "dtype: object\n",
      "\n",
      "Splitting average_usage column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_11748\\2305423215.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['avg_cpu_usage'] = df['average_usage'].apply(lambda x: eval(x)['cpus'])\n",
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_11748\\2305423215.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['avg_memory_usage'] = df['average_usage'].apply(lambda x: eval(x)['memory'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting maximum_usage column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_11748\\2305423215.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['max_cpu_usage'] = df['maximum_usage'].apply(lambda x: eval(x)['cpus'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing original columns...\n",
      "\n",
      "New columns after splitting:\n",
      "['resource_request', 'cpu_usage_distribution', 'tail_cpu_usage_distribution', 'assigned_memory', 'page_cache_memory', 'duration', 'vertical_scaling', 'event', 'failed', 'avg_cpu_usage', 'avg_memory_usage', 'max_cpu_usage', 'max_memory_usage']\n",
      "\n",
      "Sample of split columns:\n",
      "   avg_cpu_usage  avg_memory_usage  max_cpu_usage  max_memory_usage\n",
      "0       0.004662      5.920410e-03       0.011902      5.935669e-03\n",
      "1       0.000000      9.536743e-07       0.000000      9.536743e-07\n",
      "2       0.024200      2.788544e-03       0.060059      2.845764e-03\n",
      "3       0.047607      3.442383e-02       0.133301      3.466797e-02\n",
      "4       0.000271      7.629395e-05       0.000415      7.629395e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_11748\\2305423215.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['max_memory_usage'] = df['maximum_usage'].apply(lambda x: eval(x)['memory'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Print data types to verify which columns need splitting\n",
    "print(\"\\nChecking data types of columns:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Step 2: Split average_usage into CPU and memory components\n",
    "print(\"\\nSplitting average_usage column...\")\n",
    "df['avg_cpu_usage'] = df['average_usage'].apply(lambda x: eval(x)['cpus'])\n",
    "df['avg_memory_usage'] = df['average_usage'].apply(lambda x: eval(x)['memory'])\n",
    "\n",
    "# Step 3: Split maximum_usage into CPU and memory components \n",
    "print(\"\\nSplitting maximum_usage column...\")\n",
    "df['max_cpu_usage'] = df['maximum_usage'].apply(lambda x: eval(x)['cpus'])\n",
    "df['max_memory_usage'] = df['maximum_usage'].apply(lambda x: eval(x)['memory'])\n",
    "\n",
    "# Step 4: Drop the original columns since we've split them\n",
    "print(\"\\nRemoving original columns...\")\n",
    "df = df.drop(['average_usage', 'maximum_usage'], axis=1)\n",
    "\n",
    "# Step 5: Verify the new columns\n",
    "print(\"\\nNew columns after splitting:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Step 6: Show sample of new columns to verify data\n",
    "print(\"\\nSample of split columns:\")\n",
    "print(df[['avg_cpu_usage', 'avg_memory_usage', 'max_cpu_usage', 'max_memory_usage']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting resource_request column...\n",
      "\n",
      "Sample of split columns:\n",
      "   requested_cpus  requested_memory\n",
      "0        0.020660          0.014435\n",
      "1        0.007240          0.001303\n",
      "2        0.048584          0.004166\n",
      "3        0.070435          0.041626\n",
      "4        0.002449          0.000232\n",
      "\n",
      "Verifying columns after splitting:\n",
      "['cpu_usage_distribution', 'tail_cpu_usage_distribution', 'assigned_memory', 'page_cache_memory', 'duration', 'vertical_scaling', 'event', 'failed', 'avg_cpu_usage', 'avg_memory_usage', 'max_cpu_usage', 'max_memory_usage', 'requested_cpus', 'requested_memory']\n",
      "\n",
      "Saving modified dataset...\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "def extract_resource_value(x, key):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return ast.literal_eval(x)[key]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Split resource_request into requested_cpus and requested_memory\n",
    "print(\"\\nSplitting resource_request column...\")\n",
    "df['requested_cpus'] = df['resource_request'].apply(lambda x: extract_resource_value(x, 'cpus'))\n",
    "df['requested_memory'] = df['resource_request'].apply(lambda x: extract_resource_value(x, 'memory'))\n",
    "\n",
    "# Drop the original resource_request column\n",
    "df = df.drop('resource_request', axis=1)\n",
    "\n",
    "# Show sample of new columns\n",
    "print(\"\\nSample of split columns:\")\n",
    "print(df[['requested_cpus', 'requested_memory']].head())\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"\\nVerifying columns after splitting:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Save the modified dataset\n",
    "print(\"\\nSaving modified dataset...\")\n",
    "df.to_csv('final_resource.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAIL' 'SCHEDULE' 'FINISH' 'ENABLE' 'EVICT' 'LOST' 'KILL'\n",
      " 'UPDATE_PENDING' 'QUEUE' 'UPDATE_RUNNING']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"event\"].unique())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
